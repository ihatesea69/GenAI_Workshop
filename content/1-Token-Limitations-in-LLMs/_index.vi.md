---
title: "Gi·ªõi h·∫°n Token trong Large Language Models"
date: 2024-02-01
draft: false
weight: 1
---

## V·∫•n ƒë·ªÅ
Large Language Models (LLMs) g·∫∑p h·∫°n ch·∫ø ƒë√°ng k·ªÉ v·ªÅ gi·ªõi h·∫°n token, g√¢y kh√≥ khƒÉn trong vi·ªác x·ª≠ l√Ω c√°c t√†i li·ªáu l·ªõn (v√≠ d·ª•: b√°o c√°o 20 trang) m·ªôt c√°ch hi·ªáu qu·∫£. H·∫°n ch·∫ø n√†y ·∫£nh h∆∞·ªüng ƒë·∫øn kh·∫£ nƒÉng hi·ªÉu v√† t·∫°o ph·∫£n h·ªìi d·ª±a tr√™n ng·ªØ c·∫£nh l·ªõn c·ªßa m√¥ h√¨nh.

![Token Limitations](/images/token_limit.jpg)

## Gi·∫£i ph√°p

### 1. Chi·∫øn l∆∞·ª£c "Chia ƒê·ªÉ Tr·ªã"
```python
text_splitter = CharacterTextSplitter(
    separator="\n",
    chunk_size=512,
    chunk_overlap=50,
    length_function=len
)
```
- **K√≠ch th∆∞·ªõc chunk**: 512 k√Ω t·ª± m·ªói chunk
- **ƒê·ªô ch·ªìng l·∫•p**: 50 k√Ω t·ª± ƒë·ªÉ duy tr√¨ t√≠nh li√™n t·ª•c ng·ªØ c·∫£nh
- **D·∫•u ph√¢n t√°ch**: K√Ω t·ª± xu·ªëng d√≤ng cho c√°c ƒëi·ªÉm ng·∫Øt t·ª± nhi√™n

### 2. Tri·ªÉn khai Vector Storage
```python
embeddings = OpenAIEmbeddings()
vectorstore = FAISS.from_texts(chunks, embeddings)
```
- S·ª≠ d·ª•ng m√¥ h√¨nh embedding c·ªßa OpenAI
- FAISS cho t√¨m ki·∫øm t∆∞∆°ng ƒë·ªìng hi·ªáu qu·∫£
- L∆∞u tr·ªØ vector trong b·ªô nh·ªõ ƒë·ªÉ truy xu·∫•t nhanh

### 3. RAG (Retrieval Augmented Generation)
```python
qa_chain = RetrievalQA.from_chain_type(
    llm=OpenAI(),
    chain_type="stuff",
    retriever=vectorstore.as_retriever(search_kwargs={"k": 3})
)
```
- Truy xu·∫•t 3 chunk li√™n quan nh·∫•t
- K·∫øt h·ª£p c√°c chunk ƒë·ªÉ t·∫°o ph·∫£n h·ªìi c√≥ ng·ªØ c·∫£nh
- S·ª≠ d·ª•ng LLM c·ªßa OpenAI ƒë·ªÉ t·∫°o ph·∫£n h·ªìi

## T√≠nh nƒÉng

### X·ª≠ l√Ω T√†i li·ªáu
- H·ªó tr·ª£ nhi·ªÅu ƒë·ªãnh d·∫°ng file (TXT, PDF, DOCX)
- Ch·ª©c nƒÉng xem tr∆∞·ªõc t√†i li·ªáu
- Theo d√µi ti·∫øn tr√¨nh x·ª≠ l√Ω

### X·ª≠ l√Ω Truy v·∫•n
- Nh·∫≠p c√¢u h·ªèi t∆∞∆°ng t√°c
- Hi·ªÉn th·ªã c√°c chunk t√†i li·ªáu li√™n quan
- Ph·∫£n h·ªìi AI d·ª±a tr√™n ng·ªØ c·∫£nh

### Giao di·ªán Ng∆∞·ªùi d√πng
- Giao di·ªán Streamlit tr·ª±c quan
- Ch·ªâ b√°o ti·∫øn tr√¨nh
- Ph·∫ßn k·∫øt qu·∫£ c√≥ th·ªÉ m·ªü r·ªông

## V√≠ d·ª• Tri·ªÉn khai

```python
# Upload v√† x·ª≠ l√Ω t√†i li·ªáu
uploaded_file = st.file_uploader("üìÑ T·∫£i l√™n t√†i li·ªáu", type=["txt", "pdf", "docx"])
if uploaded_file is not None:
    text = uploaded_file.read().decode("utf-8")
    
    # X·ª≠ l√Ω chunk
    chunks = text_splitter.split_text(text)
    
    # L∆∞u tr·ªØ vector
    vectorstore = FAISS.from_texts(chunks, embeddings)
    
    # X·ª≠ l√Ω truy v·∫•n
    query = st.text_input("ƒê·∫∑t c√¢u h·ªèi c·ªßa b·∫°n:")
    if query:
        docs = vectorstore.similarity_search(query, k=3)
        response = qa_chain.run(query)
```

## Best Practices

1. **Ti·ªÅn x·ª≠ l√Ω**
   - L√†m s·∫°ch v√† chu·∫©n h√≥a vƒÉn b·∫£n tr∆∞·ªõc khi chia nh·ªè
   - Lo·∫°i b·ªè n·ªôi dung kh√¥ng li√™n quan ƒë·ªÉ t·ªëi ∆∞u h√≥a token
   - Duy tr√¨ c·∫•u tr√∫c t√†i li·ªáu khi c√≥ th·ªÉ

2. **Chi·∫øn l∆∞·ª£c Chia nh·ªè**
   - ƒêi·ªÅu ch·ªânh k√≠ch th∆∞·ªõc chunk d·ª±a tr√™n lo·∫°i n·ªôi dung
   - S·ª≠ d·ª•ng ƒë·ªô ch·ªìng l·∫•p ph√π h·ª£p ƒë·ªÉ b·∫£o to√†n ng·ªØ c·∫£nh
   - Xem x√©t ranh gi·ªõi ng·ªØ nghƒ©a khi c√≥ th·ªÉ

3. **T·ªëi ∆∞u h√≥a Truy v·∫•n**
   - Tri·ªÉn khai cache cho c√°c truy v·∫•n th∆∞·ªùng xuy√™n
   - T·ªëi ∆∞u s·ªë l∆∞·ª£ng chunk ƒë∆∞·ª£c truy xu·∫•t
   - C√¢n b·∫±ng ch·∫•t l∆∞·ª£ng ph·∫£n h·ªìi v·ªõi t·ªëc ƒë·ªô x·ª≠ l√Ω

## C√¢n nh·∫Øc v·ªÅ Hi·ªáu nƒÉng

1. **S·ª≠ d·ª•ng B·ªô nh·ªõ**
   - Gi√°m s√°t k√≠ch th∆∞·ªõc vector store
   - Tri·ªÉn khai x·ª≠ l√Ω h√†ng lo·∫°t cho t√†i li·ªáu l·ªõn
   - D·ªçn d·∫πp b·ªô nh·ªõ t·∫°m

2. **Th·ªùi gian Ph·∫£n h·ªìi**
   - Cache c√°c truy v·∫•n ph·ªï bi·∫øn
   - T·ªëi ∆∞u h√≥a truy xu·∫•t chunk
   - C√¢n b·∫±ng k√≠ch th∆∞·ªõc chunk v·ªõi ƒë·ªô ch√≠nh x√°c

3. **ƒê·ªô ch√≠nh x√°c**
   - X√°c th·ª±c ph·∫£n h·ªìi v·ªõi t√†i li·ªáu ngu·ªìn
   - ƒêi·ªÅu ch·ªânh k√≠ch th∆∞·ªõc chunk d·ª±a tr√™n ƒë·ªô ph·ª©c t·∫°p n·ªôi dung
   - Gi√°m s√°t v√† ghi log ch·∫•t l∆∞·ª£ng truy xu·∫•t

